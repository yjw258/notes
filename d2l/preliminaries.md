# 预备知识

## 1. 数据操作

### 1.1 入门

* 使用 **arange** 创建一个行向量 x。

  ```python
  x = x.arange(12)
  ```

  ```
  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
  ```

* 通过 **shape** 属性访问张量的形状。

  ```python
  x.shape
  ```

  ```
  torch.Size([12])
  ```

* 调用 **numel()** 获得张量中元素的总数，即形状的所有元素乘积。

  ```python
  x.numel()
  ```

  ```
  12
  ```

* 调用 **reshape** 函数，改变一个张量的形状而不改变元素数量和元素值。

  ```python
  X = x.reshape(3, 4)
  ```

  ```
  tensor([[0, 1, 2, 3],
  		[4, 5, 6, 7],
  		[8, 9, 10, 11]])
  ```

  可以通过参数 -1 来自动计算维度。例如：可以用 `x.reshape(-1, 4)`或 `x.reshape(3, -1)`来取代`x.reshape(3, 4)`。

* 调用 **torch.zeros()** 创建全0张量。

  ```python
  torch.zeros((2, 3, 4))
  ```

  ```
  tensor([[[0., 0., 0., 0.],
  		 [0., 0., 0., 0.],
  		 [0., 0., 0., 0.]],
  		 
  		[[0., 0., 0., 0.],
  		 [0., 0., 0., 0.],
  		 [0., 0., 0., 0.]]])
  ```

* 调用 **torch.ones()** 创建全1张量。

  ```python
  torch.ones((2, 3, 4))
  ```

   ```
   tensor([[[1., 1., 1., 1.],
   		 [1., 1., 1., 1.],
   		 [1., 1., 1., 1.]],
   		 
   		[[1., 1., 1., 1.],
   		 [1., 1., 1., 1.],
   		 [1., 1., 1., 1.]]])
   ```

* 调用 **torch.randn()** 创建一个张量，其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样。

  ```python
  torch.randn(3,4)
  ```

  ```
  tensor([[ 0.7277, -1.3848, -0.2607,  0.9701],
          [-2.3290, -0.3754,  0.2457,  0.0760],
          [-1.2832, -0.3600, -0.3321,  0.8184]])
  ```

* 通过提供包含数值的Python列表来为所需张量中的每个元素赋予确定值。

  ```python
  torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
  ```

  ```
  tensor([[2, 1, 4, 3],
          [1, 2, 3, 4],
          [4, 3, 2, 1]])
  ```

### 1.2 运算符

* 按元素运算：

  ```python
  x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算
  ```

  ```python
  torch.exp(x)
  ```

* 调用 **torch.cat()** 连结多个张量，dim 参数决定沿哪个轴连结：

  ```python
  X = torch.arange(12, dtype=torch.float32).reshape((3,4))
  Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
  torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)
  ```

  ```
  (tensor([[ 0.,  1.,  2.,  3.],
           [ 4.,  5.,  6.,  7.],
           [ 8.,  9., 10., 11.],
           [ 2.,  1.,  4.,  3.],
           [ 1.,  2.,  3.,  4.],
           [ 4.,  3.,  2.,  1.]]),
   tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],
           [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],
           [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))
  ```

* 通过逻辑运算符构建二元张量。以 `X==Y` 为例：

  ```python
  X == Y
  ```

  ```
  tensor([[False,  True, False,  True],
          [False, False, False, False],
          [False, False, False, False]])
  ```

  **X<Y和X>Y** 同理。

* 调用 **sum()** 对张量中的所有元素进行求和，会产生一个单元素张量：

  ```python
  X.sum()
  ```

  ```
  tensor(66.)
  ```

### 1.3 广播机制

在某些情况下，即使形状不同，我们仍然可以通过调用 **广播机制** 来执行按元素操作。

```python
a = torch.arange(3).reshape((3, 1))
b = torch.arange(2).reshape((1, 2))
```

```
(tensor([[0],
		[1],
		[2]]),
 tensor([[0, 1]]))
```

```python
a + b
```

```
tensor([[0, 1],
	    [1, 2],
	    [2, 3]])
```

### 1.4 索引和切片

张量与任何Python数组一样：第一个元素的索引是0，最后一个元素索引是-1。

除读取外，还可以通过指定索引将元素写入矩阵：

```python
X[1, 2] = 9
```

```
tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  5.,  9.,  7.],
        [ 8.,  9., 10., 11.]])
```

还可以为多个元素赋值相同的值：

```python
X[0:2, :] = 12
```

```
tensor([[12., 12., 12., 12.],
        [12., 12., 12., 12.],
        [ 8.,  9., 10., 11.]])
```

### 1.5 节省内存

运行一些操作可能会导致为新结果分配内存。例如：如果我们用 **Y = X + Y** ，我们将取消引用Y指向的张量，而是指向新分配的内存处的张量。

Python 的 **id()** 函数给我们提供了内存中引用对象的确切地址。

```python
before = id(Y)
Y = Y + X
id(Y) == before
```

```python
False
```

正确方法：**X[ : ] = X + Y 或 X += Y**

```python
before = id(X)
X += Y
id(X) == before
```

```python
True
```

### 1.6 转换为其他Python对象

* torch张量与NumPy张量互相转换：

  ```python
  A = X.numpy()
  B = torch.tensor(A)
  type(A), type(B)
  ```

  ```
  (numpy.ndarray, torch.Tensor)
  ```

* 调用**item函数或Python内置函数**，将大小为1的张量转换为 Python 标量：

  ```python
  a = torch.tensor([3.5])
  a, a.item(), float(a), int(a)
  ```

  ```
  (tensor([3.5000]), 3.5, 3.5 ,3)
  ```